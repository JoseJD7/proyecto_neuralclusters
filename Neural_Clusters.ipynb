{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Clusters.ipynb ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILrFj60aE-XA",
        "colab_type": "text"
      },
      "source": [
        "In a *regression* problem, we aim to predict the output of a continuous value, like a price or a probability. Contrast this with a *classification* problem, where we aim to select a class from a list of classes (for example, where a picture contains an apple or an orange, recognizing which fruit is in the picture).\n",
        "\n",
        "This notebook uses the classic [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) Dataset and builds a model to predict the fuel efficiency of late-1970s and early 1980s automobiles. To do this, we'll provide the model with a description of many automobiles from that time period. This description includes attributes like: cylinders, displacement, horsepower, and weight.\n",
        "\n",
        "This example uses the `tf.keras` API, see [this guide](https://www.tensorflow.org/guide/keras) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3BVRc6M-Ci8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --pre --quiet astroquery"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5_yOjQBE4gz",
        "colab_type": "code",
        "outputId": "b097c832-dca1-4590-d272-6fc57c7959b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pathlib\n",
        "from astroquery.sdss import SDSS\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnipyp1PEwNi",
        "colab_type": "text"
      },
      "source": [
        "## The Auto MPG dataset\n",
        "\n",
        "The dataset is available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n",
        "\n",
        "### Get the data\n",
        "First download the dataset.-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3cvu2Kj-iOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tdata = SDSS.query_sql(\"\"\"SELECT TOP 1000\n",
        "                      p.fiberMag_u, p.fiberMag_g, p.fiberMag_r, p.fiberMag_i, \n",
        "                      p.fiberMag_z,s.elodieTEff\n",
        "                   \n",
        "                      \n",
        "                      FROM PhotoObjAll AS p JOIN specObjAll s ON s.bestobjid = p.objid\n",
        "                      \n",
        "                      WHERE p.mode = 1 AND s.sciencePrimary = 1 AND p.clean = 1 AND s.class != 'QSO' AND s.class !='GALAXY'\n",
        "                      \n",
        "                      \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYU1l2WHCUJI",
        "colab_type": "code",
        "outputId": "9202b019-039e-487c-863b-595713dd17e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1147
        }
      },
      "source": [
        "datapd=data.to_pandas()\n",
        "print(datapd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     fiberMag_u  fiberMag_g  fiberMag_r  fiberMag_i  fiberMag_z  elodieTEff\n",
            "0      21.83404    19.30373    17.88528    16.98804    16.41673        3980\n",
            "1      19.36734    18.48736    18.15342    18.01115    17.91279        6000\n",
            "2      19.42088    17.92244    17.13913    16.93484    16.73513        5000\n",
            "3      19.15921    19.11771    19.36260    19.59598    19.76112        7652\n",
            "4      18.80860    16.28457    15.33544    15.01370    14.78891        4528\n",
            "5      24.39023    22.70759    20.93211    19.90295    19.12873        3717\n",
            "6      17.93162    16.81432    16.49228    16.27050    16.17541        5860\n",
            "7      16.02642    15.04047    14.88521    14.74759    14.71799        7000\n",
            "8      20.74338    19.80917    19.62092    19.54036    19.61644        6597\n",
            "9      21.84291    19.61091    18.44390    17.95710    17.71370        4382\n",
            "10     18.81515    17.75691    17.59942    17.58388    17.64050        7000\n",
            "11     17.04001    15.99135    15.63882    15.49512    15.45219        6000\n",
            "12     20.01661    19.08842    18.87573    18.84942    18.88937        7000\n",
            "13     18.53829    17.70830    17.49582    17.42422    17.39282        6500\n",
            "14     18.31656    17.22207    16.84874    16.69852    16.67533        5790\n",
            "15     20.42932    19.21972    19.33791    19.48376    19.61967        7828\n",
            "16     22.53658    20.94134    19.76979    19.31565    19.10286        4353\n",
            "17     20.40858    19.38835    19.21127    19.17124    19.27729        7000\n",
            "18     18.81907    17.55618    17.70665    17.86166    17.94942        7852\n",
            "19     18.40986    17.30778    16.94170    16.81517    16.76395        5873\n",
            "20     18.70556    17.67099    17.50982    17.47872    17.47322        7500\n",
            "21     21.45768    21.03009    20.56853    20.16531    20.17874        6361\n",
            "22     18.94252    17.76225    17.52687    17.45880    17.47992        7000\n",
            "23     20.32955    19.44499    19.26869    19.22072    19.19315        7000\n",
            "24     20.77047    19.76856    19.63047    19.58318    19.51106        6684\n",
            "25     18.32646    16.87246    16.35249    16.17901    16.09872        5426\n",
            "26     22.60329    21.06668    20.41005    19.89810    19.56415        3820\n",
            "27     20.94506    19.84256    19.27444    19.03583    19.34989        5320\n",
            "28     19.81315    18.82988    18.67148    18.64071    18.64509        6500\n",
            "29     18.86143    17.64072    17.19955    17.05950    17.00875        5630\n",
            "..          ...         ...         ...         ...         ...         ...\n",
            "970    18.05586    16.95689    16.54857    16.39654    16.35527        5613\n",
            "971    20.08330    18.57928    17.95527    17.69211    17.55805        5047\n",
            "972    17.60504    16.67176    16.40761    16.30771    16.29283        6500\n",
            "973    21.79914    20.36521    19.74117    19.19592    18.70957        3717\n",
            "974    20.33459    17.62245    16.18571    15.48598    15.19682        3858\n",
            "975    18.90818    19.19697    19.70649    20.02505    20.43589        9640\n",
            "976    21.62818    19.12069    17.73739    16.57405    15.91977        3717\n",
            "977    20.57030    19.00186    18.17631    17.82590    17.60359        4576\n",
            "978    18.08881    17.15762    16.80878    16.67418    16.62086        6000\n",
            "979    20.37630    19.33138    19.17400    19.15765    19.04840        7000\n",
            "980    20.87237    19.79620    19.63093    19.61628    19.58749        7500\n",
            "981    19.31227    18.11338    18.24332    18.37334    18.41776        8500\n",
            "982    18.19648    18.11402    18.13847    18.29888    18.39126        6000\n",
            "983    17.75781    16.56921    16.30493    16.20382    16.15643        6500\n",
            "984    19.38565    18.42801    18.09449    17.95390    17.90805        6000\n",
            "985    19.99402    18.91639    18.73441    18.69574    18.71792        7500\n",
            "986    19.40395    18.32555    18.29806    18.33450    18.35410        8500\n",
            "987    17.29819    16.43928    16.66172    16.89840    17.01900        9640\n",
            "988    18.98217    19.48862    20.00030    20.40855    20.75096        9899\n",
            "989    19.31137    19.08472    19.35039    19.62811    20.20988        9000\n",
            "990    16.92259    15.89803    15.69435    15.62743    15.66356        7000\n",
            "991    20.64265    18.18595    17.09124    16.68753    16.45831        4382\n",
            "992    19.86127    19.35422    19.44884    19.67858    20.16969        7652\n",
            "993    18.46796    17.29116    16.88975    16.75507    16.70002        5659\n",
            "994    19.06044    18.00112    17.97834    17.99776    18.05201        7500\n",
            "995    19.16299    18.17529    17.82271    17.74182    17.70380        6000\n",
            "996    19.78176    18.80128    18.40997    18.25500    18.22495        6000\n",
            "997    19.34934    18.39547    18.10792    17.95883    17.91736        5961\n",
            "998    18.38475    17.25642    17.29911    17.34172    17.40492        8500\n",
            "999    22.43204    20.02917    18.62167    17.97240    17.59883        3858\n",
            "\n",
            "[1000 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMkHiqp_EtWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "#dataset_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1RtaBFkEpvW",
        "colab_type": "text"
      },
      "source": [
        "Import it using pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbqnaZgMEOdV",
        "colab_type": "text"
      },
      "source": [
        "### Split the data into train and test\n",
        "\n",
        "Now split the dataset into a training set and a test set.\n",
        "\n",
        "We will use the test set in the final evaluation of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytPIaTCAEMqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datapd = datapd.sample(frac=0.8,random_state=0)\n",
        "test_datapd = datapd.drop(train_datapd.index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un9FMCKeEKJk",
        "colab_type": "text"
      },
      "source": [
        "### Inspect the data\n",
        "\n",
        "Have a quick look at the joint distribution of a few pairs of columns from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1kwsyElEIF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sns.pairplot(train_datapd[[\"fiberMag_u\", \"fiberMag_g\", \"fiberMag_r\", \"fiberMag_i\",\"fiberMag_z\",\"elodieTEff\"]], diag_kind=\"kde\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJMy5AApEEMv",
        "colab_type": "text"
      },
      "source": [
        "Also look at the overall statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXMZjr7HEBTf",
        "colab_type": "code",
        "outputId": "b701cabd-4760-4e79-bfe8-ee10bb8efc46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "\n",
        "train_stats = train_datapd.describe()\n",
        "train_stats.pop(\"elodieTEff\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fiberMag_u</th>\n",
              "      <td>800.0</td>\n",
              "      <td>20.098393</td>\n",
              "      <td>1.895006</td>\n",
              "      <td>14.25133</td>\n",
              "      <td>18.843650</td>\n",
              "      <td>19.755265</td>\n",
              "      <td>21.322480</td>\n",
              "      <td>25.97398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiberMag_g</th>\n",
              "      <td>800.0</td>\n",
              "      <td>18.723378</td>\n",
              "      <td>1.628038</td>\n",
              "      <td>14.73260</td>\n",
              "      <td>17.670190</td>\n",
              "      <td>18.686685</td>\n",
              "      <td>19.521535</td>\n",
              "      <td>25.53572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiberMag_r</th>\n",
              "      <td>800.0</td>\n",
              "      <td>18.183431</td>\n",
              "      <td>1.428785</td>\n",
              "      <td>14.88521</td>\n",
              "      <td>17.246405</td>\n",
              "      <td>18.110275</td>\n",
              "      <td>18.857825</td>\n",
              "      <td>23.71967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiberMag_i</th>\n",
              "      <td>800.0</td>\n",
              "      <td>17.865310</td>\n",
              "      <td>1.287266</td>\n",
              "      <td>14.74759</td>\n",
              "      <td>17.001860</td>\n",
              "      <td>17.763330</td>\n",
              "      <td>18.698310</td>\n",
              "      <td>21.98211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiberMag_z</th>\n",
              "      <td>800.0</td>\n",
              "      <td>17.707342</td>\n",
              "      <td>1.304314</td>\n",
              "      <td>14.66739</td>\n",
              "      <td>16.766065</td>\n",
              "      <td>17.638395</td>\n",
              "      <td>18.491230</td>\n",
              "      <td>22.25513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            count       mean       std  ...        50%        75%       max\n",
              "fiberMag_u  800.0  20.098393  1.895006  ...  19.755265  21.322480  25.97398\n",
              "fiberMag_g  800.0  18.723378  1.628038  ...  18.686685  19.521535  25.53572\n",
              "fiberMag_r  800.0  18.183431  1.428785  ...  18.110275  18.857825  23.71967\n",
              "fiberMag_i  800.0  17.865310  1.287266  ...  17.763330  18.698310  21.98211\n",
              "fiberMag_z  800.0  17.707342  1.304314  ...  17.638395  18.491230  22.25513\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAH7deWED8tk",
        "colab_type": "text"
      },
      "source": [
        "### Split features from labels\n",
        "\n",
        "Separate the target value, or \"label\", from the features. This label is the value that you will train the model to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PsmBwsvD55i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_datapd.pop('elodieTEff')\n",
        "test_labels = test_datapd.pop('elodieTEff')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2fH1vq7D1Tw",
        "colab_type": "text"
      },
      "source": [
        "### Normalize the data\n",
        "\n",
        "Look again at the `train_stats` block above and note how different the ranges of each feature are.\n",
        "\n",
        "It is good practice to normalize features that use different scales and ranges. Although the model *might* converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input.\n",
        "\n",
        "Note: Although we intentionally generate these statistics from only the training dataset, these statistics will also be used to normalize the test dataset. We need to do that to project the test dataset into the same distribution that the model has been trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgbVr0RWSsom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normaalizar train label\n",
        "def normlabels(x):\n",
        "  r=(x-x.mean())/x.std()\n",
        "  return r\n",
        "#normalizar train feat\n",
        "def normfeat(x):\n",
        "  r=(x-x.mean())/x.std()\n",
        "  return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWW9QfEXDxnA",
        "colab_type": "code",
        "outputId": "b0739630-b8eb-4887-fff4-8b6e9df5e6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1092
        }
      },
      "source": [
        "\n",
        "#normtest_temp=tf.keras.utils.normalize(test_labels,axis=0)\n",
        "train_mean=train_labels.mean()\n",
        "train_std=train_labels.std()\n",
        "norm_trainlabels=(train_labels-train_mean)/train_std\n",
        "print(norm_trainlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "993   -0.124885\n",
            "859   -0.297759\n",
            "298   -1.150643\n",
            "553    0.299441\n",
            "672    0.081233\n",
            "971   -0.494811\n",
            "27    -0.329795\n",
            "231   -1.139763\n",
            "306   -1.298734\n",
            "706   -1.213506\n",
            "496    1.592367\n",
            "558    2.231878\n",
            "784    0.081233\n",
            "239    0.987913\n",
            "578    0.081233\n",
            "55     0.383460\n",
            "906   -0.367876\n",
            "175   -0.045702\n",
            "14    -0.045702\n",
            "77     0.383460\n",
            "31    -1.298734\n",
            "481   -0.350951\n",
            "310   -1.298734\n",
            "311   -0.487557\n",
            "883    0.104202\n",
            "788   -0.045702\n",
            "45    -0.014875\n",
            "103    0.987913\n",
            "760    0.987913\n",
            "1      0.081233\n",
            "         ...   \n",
            "216   -0.142414\n",
            "735   -1.298734\n",
            "129    1.592367\n",
            "349   -0.896772\n",
            "111    0.081233\n",
            "166   -0.350951\n",
            "207   -0.365458\n",
            "438   -0.914301\n",
            "552   -1.139763\n",
            "274   -0.350951\n",
            "974   -1.213506\n",
            "591    0.685687\n",
            "800    0.081233\n",
            "937    0.987913\n",
            "525    0.987913\n",
            "287   -1.298734\n",
            "469   -0.329795\n",
            "326   -1.139763\n",
            "121    1.592367\n",
            "994    0.987913\n",
            "507    0.081233\n",
            "228    0.987913\n",
            "673   -0.365458\n",
            "595    0.081233\n",
            "445    0.104202\n",
            "117    0.908125\n",
            "464    0.987913\n",
            "25    -0.265723\n",
            "110    1.592367\n",
            "149   -1.298734\n",
            "Name: elodieTEff, Length: 800, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di-_dkBrDrul",
        "colab_type": "text"
      },
      "source": [
        "This normalized data is what we will use to train the model.\n",
        "\n",
        "Caution: The statistics used to normalize the inputs here (mean and standard deviation) need to be applied to any other data that is fed to the model, along with the one-hot encoding that we did earlier.  That includes the test set as well as live data when the model is used in production.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9KUKRQFDlPn",
        "colab_type": "text"
      },
      "source": [
        "## The model\n",
        "\n",
        "### Build the model\n",
        "\n",
        "Let's build our model. Here, we'll use a `Sequential` model with two densely connected hidden layers, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model`, since we'll create a second model, later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asg0O1TLDjAy",
        "colab_type": "code",
        "outputId": "19469d1e-77c3-4f68-e100-d12e744141a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(1, activation=tf.nn.sigmoid, input_shape=[len(train_datapd.keys())]),\n",
        "    #layers.Dense(4, activation=tf.nn.relu),\n",
        "    #layers.Dense(4, activation=tf.nn.relu),\n",
        "    #layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "  return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LaH9J7aDb1B",
        "colab_type": "text"
      },
      "source": [
        "### Inspect the model\n",
        "\n",
        "Use the `.summary` method to print a simple description of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMeilODVDZ8L",
        "colab_type": "code",
        "outputId": "e2c341e2-4b24-4ddd-9b91-9bee5e24033f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUsEB_oUDR_j",
        "colab_type": "text"
      },
      "source": [
        "Now try out the model. Take a batch of `10` examples from the training data and call `model.predict` on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elZqEAdBDKF8",
        "colab_type": "text"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Train the model for 1000 epochs, and record the training and validation accuracy in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW0KSl6iDHb0",
        "colab_type": "code",
        "outputId": "c9fd939a-9b52-4680-c5aa-457b1e7e09e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  norm_traindata, norm_traintemp,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-06d9448b209d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m history = model.fit(\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mnorm_traindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_traintemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   callbacks=[PrintDot()])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'norm_traintemp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRMaIjLWDCKA",
        "colab_type": "text"
      },
      "source": [
        "Visualize the model's training progress using the stats stored in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHXhcQ-sDAN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hist = pd.DataFrame(history.history)\n",
        "#hist['epoch'] = history.epoch\n",
        "#hist.tail()\n",
        "\n",
        "print(history)\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [K]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$K^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlWek3M3CxZb",
        "colab_type": "text"
      },
      "source": [
        "This graph shows little improvement, or even degradation in the validation error after about 100 epochs. Let's update the `model.fit` call to automatically stop training when the validation score doesn't improve. We'll use an *EarlyStopping callback* that tests a training condition for  every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training.\n",
        "\n",
        "You can learn more about this callback [here](https://www.tensorflow.org/versions/master/api_docs/python/tf/keras/callbacks/EarlyStopping)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywa8UpMYCvNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(norm_traindata, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtiYPCm-CoeB",
        "colab_type": "text"
      },
      "source": [
        "The graph shows that on the validation set, the average error is usually around +/- 2 MPG. Is this good? We'll leave that decision up to you.\n",
        "\n",
        "Let's see how well the model generalizes by using the **test** set, which we did not use when training the model.  This tells us how well we can expect the model to predict when we use it in the real world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-08c5XBCl7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(norm_testdata, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} Kelvin\".format(mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3FTCj6gChEg",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions\n",
        "\n",
        "Finally, predict MPG values using data in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go8xaaLkCdxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(norm_testdata)\n",
        "\n",
        "test_predictions = model.predict(norm_testdata).flatten()\n",
        "print(test_predictions)\n",
        "\n",
        "plt.scatter(test_labels, test_predictions, color='red')\n",
        "plt.xlabel('True Values [K]')\n",
        "plt.ylabel('Predictions [K]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "#plt.xlim([0,plt.xlim()[1]])\n",
        "#plt.ylim([0,100])\n",
        "#plt.ylim([0,plt.ylim()[1]])\n",
        "#_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBQjihVVCWkc",
        "colab_type": "text"
      },
      "source": [
        "It looks like our model predicts reasonably well. Let's take a look at the error distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Re1hClCN37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [K]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-9aI2Z6CBy0",
        "colab_type": "text"
      },
      "source": [
        "It's not quite gaussian, but we might expect that because the number of samples is very small.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0udzTlbB1BF",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook introduced a few techniques to handle a regression problem.\n",
        "\n",
        "* Mean Squared Error (MSE) is a common loss function used for regression problems (different loss functions are used for classification problems).\n",
        "* Similarly, evaluation metrics used for regression differ from classification. A common regression metric is Mean Absolute Error (MAE).\n",
        "* When numeric input data features have values with different ranges, each feature should be scaled independently to the same range.\n",
        "* If there is not much training data, one technique is to prefer a small network with few hidden layers to avoid overfitting.\n",
        "* Early stopping is a useful technique to prevent overfitting.\n"
      ]
    }
  ]
}